{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2017-present, Facebook, Inc.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import fasttext_pybind as fasttext\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import sys\n",
    "from itertools import chain\n",
    "\n",
    "loss_name = fasttext.loss_name\n",
    "model_name = fasttext.model_name\n",
    "EOS = \"</s>\"\n",
    "BOW = \"<\"\n",
    "EOW = \">\"\n",
    "\n",
    "displayed_errors = {}\n",
    "\n",
    "\n",
    "class _Meter(object):\n",
    "    def __init__(self, fasttext_model, meter):\n",
    "        self.f = fasttext_model\n",
    "        self.m = meter\n",
    "\n",
    "    def score_vs_true(self, label):\n",
    "        \"\"\"Return scores and the gold of each sample for a specific label\"\"\"\n",
    "        label_id = self.f.get_label_id(label)\n",
    "        pair_list = self.m.scoreVsTrue(label_id)\n",
    "\n",
    "        if pair_list:\n",
    "            y_scores, y_true = zip(*pair_list)\n",
    "        else:\n",
    "            y_scores, y_true = ([], ())\n",
    "\n",
    "        return np.array(y_scores, copy=False), np.array(y_true, copy=False)\n",
    "\n",
    "    def precision_recall_curve(self, label=None):\n",
    "        \"\"\"Return precision/recall curve\"\"\"\n",
    "        if label:\n",
    "            label_id = self.f.get_label_id(label)\n",
    "            pair_list = self.m.precisionRecallCurveLabel(label_id)\n",
    "        else:\n",
    "            pair_list = self.m.precisionRecallCurve()\n",
    "\n",
    "        if pair_list:\n",
    "            precision, recall = zip(*pair_list)\n",
    "        else:\n",
    "            precision, recall = ([], ())\n",
    "\n",
    "        return np.array(precision, copy=False), np.array(recall, copy=False)\n",
    "\n",
    "    def precision_at_recall(self, recall, label=None):\n",
    "        \"\"\"Return precision for a given recall\"\"\"\n",
    "        if label:\n",
    "            label_id = self.f.get_label_id(label)\n",
    "            precision = self.m.precisionAtRecallLabel(label_id, recall)\n",
    "        else:\n",
    "            precision = self.m.precisionAtRecall(recall)\n",
    "\n",
    "        return precision\n",
    "\n",
    "    def recall_at_precision(self, precision, label=None):\n",
    "        \"\"\"Return recall for a given precision\"\"\"\n",
    "        if label:\n",
    "            label_id = self.f.get_label_id(label)\n",
    "            recall = self.m.recallAtPrecisionLabel(label_id, precision)\n",
    "        else:\n",
    "            recall = self.m.recallAtPrecision(precision)\n",
    "\n",
    "        return recall\n",
    "\n",
    "\n",
    "class _FastText(object):\n",
    "    \"\"\"\n",
    "    This class defines the API to inspect models and should not be used to\n",
    "    create objects. It will be returned by functions such as load_model or\n",
    "    train.\n",
    "\n",
    "    In general this API assumes to be given only unicode for Python2 and the\n",
    "    Python3 equvalent called str for any string-like arguments. All unicode\n",
    "    strings are then encoded as UTF-8 and fed to the fastText C++ API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_path=None, args=None):\n",
    "        self.f = fasttext.fasttext()\n",
    "        if model_path is not None:\n",
    "            self.f.loadModel(model_path)\n",
    "        self._words = None\n",
    "        self._labels = None\n",
    "        self.set_args(args)\n",
    "\n",
    "    def set_args(self, args=None):\n",
    "        if args:\n",
    "            arg_names = ['lr', 'dim', 'ws', 'epoch', 'minCount',\n",
    "                         'minCountLabel', 'minn', 'maxn', 'neg', 'wordNgrams',\n",
    "                         'loss', 'bucket', 'thread', 'lrUpdateRate', 't',\n",
    "                         'label', 'verbose', 'pretrainedVectors']\n",
    "            for arg_name in arg_names:\n",
    "                setattr(self, arg_name, getattr(args, arg_name))\n",
    "\n",
    "    def is_quantized(self):\n",
    "        return self.f.isQuant()\n",
    "\n",
    "    def get_dimension(self):\n",
    "        \"\"\"Get the dimension (size) of a lookup vector (hidden layer).\"\"\"\n",
    "        a = self.f.getArgs()\n",
    "        return a.dim\n",
    "\n",
    "    def get_word_vector(self, word):\n",
    "        \"\"\"Get the vector representation of word.\"\"\"\n",
    "        dim = self.get_dimension()\n",
    "        b = fasttext.Vector(dim)\n",
    "        self.f.getWordVector(b, word)\n",
    "        return np.array(b)\n",
    "\n",
    "    def get_sentence_vector(self, text):\n",
    "        \"\"\"\n",
    "        Given a string, get a single vector represenation. This function\n",
    "        assumes to be given a single line of text. We split words on\n",
    "        whitespace (space, newline, tab, vertical tab) and the control\n",
    "        characters carriage return, formfeed and the null character.\n",
    "        \"\"\"\n",
    "        if text.find('\\n') != -1:\n",
    "            raise ValueError(\n",
    "                \"predict processes one line at a time (remove \\'\\\\n\\')\"\n",
    "            )\n",
    "        text += \"\\n\"\n",
    "        dim = self.get_dimension()\n",
    "        b = fasttext.Vector(dim)\n",
    "        self.f.getSentenceVector(b, text)\n",
    "        return np.array(b)\n",
    "\n",
    "    def get_nearest_neighbors(self, word, k=10, on_unicode_error='strict'):\n",
    "        return self.f.getNN(word, k, on_unicode_error)\n",
    "\n",
    "    def get_analogies(self, wordA, wordB, wordC, k=10,\n",
    "                      on_unicode_error='strict'):\n",
    "        return self.f.getAnalogies(wordA, wordB, wordC, k, on_unicode_error)\n",
    "\n",
    "    def get_word_id(self, word):\n",
    "        \"\"\"\n",
    "        Given a word, get the word id within the dictionary.\n",
    "        Returns -1 if word is not in the dictionary.\n",
    "        \"\"\"\n",
    "        return self.f.getWordId(word)\n",
    "\n",
    "    def get_label_id(self, label):\n",
    "        \"\"\"\n",
    "        Given a label, get the label id within the dictionary.\n",
    "        Returns -1 if label is not in the dictionary.\n",
    "        \"\"\"\n",
    "        return self.f.getLabelId(label)\n",
    "\n",
    "    def get_subword_id(self, subword):\n",
    "        \"\"\"\n",
    "        Given a subword, return the index (within input matrix) it hashes to.\n",
    "        \"\"\"\n",
    "        return self.f.getSubwordId(subword)\n",
    "\n",
    "    def get_subwords(self, word, on_unicode_error='strict'):\n",
    "        \"\"\"\n",
    "        Given a word, get the subwords and their indicies.\n",
    "        \"\"\"\n",
    "        pair = self.f.getSubwords(word, on_unicode_error)\n",
    "        return pair[0], np.array(pair[1])\n",
    "\n",
    "    def get_input_vector(self, ind):\n",
    "        \"\"\"\n",
    "        Given an index, get the corresponding vector of the Input Matrix.\n",
    "        \"\"\"\n",
    "        dim = self.get_dimension()\n",
    "        b = fasttext.Vector(dim)\n",
    "        self.f.getInputVector(b, ind)\n",
    "        return np.array(b)\n",
    "\n",
    "    def predict(self, text, k=1, threshold=0.0, on_unicode_error='strict'):\n",
    "        \"\"\"\n",
    "        Given a string, get a list of labels and a list of\n",
    "        corresponding probabilities. k controls the number\n",
    "        of returned labels. A choice of 5, will return the 5\n",
    "        most probable labels. By default this returns only\n",
    "        the most likely label and probability. threshold filters\n",
    "        the returned labels by a threshold on probability. A\n",
    "        choice of 0.5 will return labels with at least 0.5\n",
    "        probability. k and threshold will be applied together to\n",
    "        determine the returned labels.\n",
    "\n",
    "        This function assumes to be given\n",
    "        a single line of text. We split words on whitespace (space,\n",
    "        newline, tab, vertical tab) and the control characters carriage\n",
    "        return, formfeed and the null character.\n",
    "\n",
    "        If the model is not supervised, this function will throw a ValueError.\n",
    "\n",
    "        If given a list of strings, it will return a list of results as usually\n",
    "        received for a single line of text.\n",
    "        \"\"\"\n",
    "\n",
    "        def check(entry):\n",
    "            if entry.find('\\n') != -1:\n",
    "                raise ValueError(\n",
    "                    \"predict processes one line at a time (remove \\'\\\\n\\')\"\n",
    "                )\n",
    "            entry += \"\\n\"\n",
    "            return entry\n",
    "\n",
    "        if type(text) == list:\n",
    "            text = [check(entry) for entry in text]\n",
    "            all_labels, all_probs = self.f.multilinePredict(\n",
    "                text, k, threshold, on_unicode_error)\n",
    "\n",
    "            return all_labels, all_probs\n",
    "        else:\n",
    "            text = check(text)\n",
    "            predictions = self.f.predict(text, k, threshold, on_unicode_error)\n",
    "            if predictions:\n",
    "                probs, labels = zip(*predictions)\n",
    "            else:\n",
    "                probs, labels = ([], ())\n",
    "\n",
    "            return labels, np.array(probs, copy=False)\n",
    "\n",
    "    def get_input_matrix(self):\n",
    "        \"\"\"\n",
    "        Get a reference to the full input matrix of a Model. This only\n",
    "        works if the model is not quantized.\n",
    "        \"\"\"\n",
    "        if self.f.isQuant():\n",
    "            raise ValueError(\"Can't get quantized Matrix\")\n",
    "        return np.array(self.f.getInputMatrix())\n",
    "\n",
    "    def get_output_matrix(self):\n",
    "        \"\"\"\n",
    "        Get a reference to the full output matrix of a Model. This only\n",
    "        works if the model is not quantized.\n",
    "        \"\"\"\n",
    "        if self.f.isQuant():\n",
    "            raise ValueError(\"Can't get quantized Matrix\")\n",
    "        return np.array(self.f.getOutputMatrix())\n",
    "\n",
    "    def get_words(self, include_freq=False, on_unicode_error='strict'):\n",
    "        \"\"\"\n",
    "        Get the entire list of words of the dictionary optionally\n",
    "        including the frequency of the individual words. This\n",
    "        does not include any subwords. For that please consult\n",
    "        the function get_subwords.\n",
    "        \"\"\"\n",
    "        pair = self.f.getVocab(on_unicode_error)\n",
    "        if include_freq:\n",
    "            return (pair[0], np.array(pair[1]))\n",
    "        else:\n",
    "            return pair[0]\n",
    "\n",
    "    def get_labels(self, include_freq=False, on_unicode_error='strict'):\n",
    "        \"\"\"\n",
    "        Get the entire list of labels of the dictionary optionally\n",
    "        including the frequency of the individual labels. Unsupervised\n",
    "        models use words as labels, which is why get_labels\n",
    "        will call and return get_words for this type of\n",
    "        model.\n",
    "        \"\"\"\n",
    "        a = self.f.getArgs()\n",
    "        if a.model == model_name.supervised:\n",
    "            pair = self.f.getLabels(on_unicode_error)\n",
    "            if include_freq:\n",
    "                return (pair[0], np.array(pair[1]))\n",
    "            else:\n",
    "                return pair[0]\n",
    "        else:\n",
    "            return self.get_words(include_freq)\n",
    "\n",
    "    def get_line(self, text, on_unicode_error='strict'):\n",
    "        \"\"\"\n",
    "        Split a line of text into words and labels. Labels must start with\n",
    "        the prefix used to create the model (__label__ by default).\n",
    "        \"\"\"\n",
    "\n",
    "        def check(entry):\n",
    "            if entry.find('\\n') != -1:\n",
    "                raise ValueError(\n",
    "                    \"get_line processes one line at a time (remove \\'\\\\n\\')\"\n",
    "                )\n",
    "            entry += \"\\n\"\n",
    "            return entry\n",
    "\n",
    "        if type(text) == list:\n",
    "            text = [check(entry) for entry in text]\n",
    "            return self.f.multilineGetLine(text, on_unicode_error)\n",
    "        else:\n",
    "            text = check(text)\n",
    "            return self.f.getLine(text, on_unicode_error)\n",
    "\n",
    "    def save_model(self, path):\n",
    "        \"\"\"Save the model to the given path\"\"\"\n",
    "        self.f.saveModel(path)\n",
    "\n",
    "    def test(self, path, k=1, threshold=0.0):\n",
    "        \"\"\"Evaluate supervised model using file given by path\"\"\"\n",
    "        return self.f.test(path, k, threshold)\n",
    "\n",
    "    def test_label(self, path, k=1, threshold=0.0):\n",
    "        \"\"\"\n",
    "        Return the precision and recall score for each label.\n",
    "\n",
    "        The returned value is a dictionary, where the key is the label.\n",
    "        For example:\n",
    "        f.test_label(...)\n",
    "        {'__label__italian-cuisine' : {'precision' : 0.7, 'recall' : 0.74}}\n",
    "        \"\"\"\n",
    "        return self.f.testLabel(path, k, threshold)\n",
    "\n",
    "    def get_meter(self, path, k=-1):\n",
    "        meter = _Meter(self, self.f.getMeter(path, k))\n",
    "\n",
    "        return meter\n",
    "\n",
    "    def quantize(\n",
    "        self,\n",
    "        input=None,\n",
    "        qout=False,\n",
    "        cutoff=0,\n",
    "        retrain=False,\n",
    "        epoch=None,\n",
    "        lr=None,\n",
    "        thread=None,\n",
    "        verbose=None,\n",
    "        dsub=2,\n",
    "        qnorm=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Quantize the model reducing the size of the model and\n",
    "        it's memory footprint.\n",
    "        \"\"\"\n",
    "        a = self.f.getArgs()\n",
    "        if not epoch:\n",
    "            epoch = a.epoch\n",
    "        if not lr:\n",
    "            lr = a.lr\n",
    "        if not thread:\n",
    "            thread = a.thread\n",
    "        if not verbose:\n",
    "            verbose = a.verbose\n",
    "        if retrain and not input:\n",
    "            raise ValueError(\"Need input file path if retraining\")\n",
    "        if input is None:\n",
    "            input = \"\"\n",
    "        self.f.quantize(\n",
    "            input, qout, cutoff, retrain, epoch, lr, thread, verbose, dsub,\n",
    "            qnorm\n",
    "        )\n",
    "\n",
    "    def set_matrices(self, input_matrix, output_matrix):\n",
    "        \"\"\"\n",
    "        Set input and output matrices. This function assumes you know what you\n",
    "        are doing.\n",
    "        \"\"\"\n",
    "        self.f.setMatrices(input_matrix.astype(np.float32),\n",
    "                           output_matrix.astype(np.float32))\n",
    "\n",
    "    @property\n",
    "    def words(self):\n",
    "        if self._words is None:\n",
    "            self._words = self.get_words()\n",
    "        return self._words\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        if self._labels is None:\n",
    "            self._labels = self.get_labels()\n",
    "        return self._labels\n",
    "\n",
    "    def __getitem__(self, word):\n",
    "        return self.get_word_vector(word)\n",
    "\n",
    "    def __contains__(self, word):\n",
    "        return word in self.words\n",
    "\n",
    "\n",
    "def _parse_model_string(string):\n",
    "    if string == \"cbow\":\n",
    "        return model_name.cbow\n",
    "    if string == \"skipgram\":\n",
    "        return model_name.skipgram\n",
    "    if string == \"supervised\":\n",
    "        return model_name.supervised\n",
    "    else:\n",
    "        raise ValueError(\"Unrecognized model name\")\n",
    "\n",
    "\n",
    "def _parse_loss_string(string):\n",
    "    if string == \"ns\":\n",
    "        return loss_name.ns\n",
    "    if string == \"hs\":\n",
    "        return loss_name.hs\n",
    "    if string == \"softmax\":\n",
    "        return loss_name.softmax\n",
    "    if string == \"ova\":\n",
    "        return loss_name.ova\n",
    "    else:\n",
    "        raise ValueError(\"Unrecognized loss name\")\n",
    "\n",
    "\n",
    "def _build_args(args, manually_set_args):\n",
    "    args[\"model\"] = _parse_model_string(args[\"model\"])\n",
    "    args[\"loss\"] = _parse_loss_string(args[\"loss\"])\n",
    "    if type(args[\"autotuneModelSize\"]) == int:\n",
    "        args[\"autotuneModelSize\"] = str(args[\"autotuneModelSize\"])\n",
    "\n",
    "    a = fasttext.args()\n",
    "    for (k, v) in args.items():\n",
    "        setattr(a, k, v)\n",
    "        if k in manually_set_args:\n",
    "            a.setManual(k)\n",
    "    a.output = \"\"  # User should use save_model\n",
    "    a.saveOutput = 0  # Never use this\n",
    "    if a.wordNgrams <= 1 and a.maxn == 0:\n",
    "        a.bucket = 0\n",
    "    return a\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Given a string of text, tokenize it and return a list of tokens\"\"\"\n",
    "    f = fasttext.fasttext()\n",
    "    return f.tokenize(text)\n",
    "\n",
    "\n",
    "def load_model(path):\n",
    "    \"\"\"Load a model given a filepath and return a model object.\"\"\"\n",
    "    return _FastText(model_path=path)\n",
    "\n",
    "\n",
    "unsupervised_default = {\n",
    "    'model': \"skipgram\",\n",
    "    'lr': 0.05,\n",
    "    'dim': 100,\n",
    "    'ws': 5,\n",
    "    'epoch': 5,\n",
    "    'minCount': 5,\n",
    "    'minCountLabel': 0,\n",
    "    'minn': 3,\n",
    "    'maxn': 6,\n",
    "    'neg': 5,\n",
    "    'wordNgrams': 1,\n",
    "    'loss': \"ns\",\n",
    "    'bucket': 2000000,\n",
    "    'thread': multiprocessing.cpu_count() - 1,\n",
    "    'lrUpdateRate': 100,\n",
    "    't': 1e-4,\n",
    "    'label': \"__label__\",\n",
    "    'verbose': 2,\n",
    "    'pretrainedVectors': \"\",\n",
    "    'seed': 0,\n",
    "    'autotuneValidationFile': \"\",\n",
    "    'autotuneMetric': \"f1\",\n",
    "    'autotunePredictions': 1,\n",
    "    'autotuneDuration': 60 * 5,  # 5 minutes\n",
    "    'autotuneModelSize': \"\"\n",
    "}\n",
    "\n",
    "\n",
    "def read_args(arg_list, arg_dict, arg_names, default_values):\n",
    "    param_map = {\n",
    "        'min_count': 'minCount',\n",
    "        'word_ngrams': 'wordNgrams',\n",
    "        'lr_update_rate': 'lrUpdateRate',\n",
    "        'label_prefix': 'label',\n",
    "        'pretrained_vectors': 'pretrainedVectors'\n",
    "    }\n",
    "\n",
    "    ret = {}\n",
    "    manually_set_args = set()\n",
    "    for (arg_name, arg_value) in chain(zip(arg_names, arg_list), arg_dict.items()):\n",
    "        if arg_name in param_map:\n",
    "            arg_name = param_map[arg_name]\n",
    "        if arg_name not in arg_names:\n",
    "            raise TypeError(\"unexpected keyword argument '%s'\" % arg_name)\n",
    "        if arg_name in ret:\n",
    "            raise TypeError(\"multiple values for argument '%s'\" % arg_name)\n",
    "        ret[arg_name] = arg_value\n",
    "        manually_set_args.add(arg_name)\n",
    "\n",
    "    for (arg_name, arg_value) in default_values.items():\n",
    "        if arg_name not in ret:\n",
    "            ret[arg_name] = arg_value\n",
    "\n",
    "    return (ret, manually_set_args)\n",
    "\n",
    "\n",
    "def train_supervised(*kargs, **kwargs):\n",
    "    \"\"\"\n",
    "    Train a supervised model and return a model object.\n",
    "\n",
    "    input must be a filepath. The input text does not need to be tokenized\n",
    "    as per the tokenize function, but it must be preprocessed and encoded\n",
    "    as UTF-8. You might want to consult standard preprocessing scripts such\n",
    "    as tokenizer.perl mentioned here: http://www.statmt.org/wmt07/baseline.html\n",
    "\n",
    "    The input file must must contain at least one label per line. For an\n",
    "    example consult the example datasets which are part of the fastText\n",
    "    repository such as the dataset pulled by classification-example.sh.\n",
    "    \"\"\"\n",
    "    supervised_default = unsupervised_default.copy()\n",
    "    supervised_default.update({\n",
    "        'lr': 0.1,\n",
    "        'minCount': 1,\n",
    "        'minn': 0,\n",
    "        'maxn': 0,\n",
    "        'loss': \"softmax\",\n",
    "        'model': \"supervised\"\n",
    "    })\n",
    "\n",
    "    arg_names = ['input', 'lr', 'dim', 'ws', 'epoch', 'minCount',\n",
    "                 'minCountLabel', 'minn', 'maxn', 'neg', 'wordNgrams', 'loss', 'bucket',\n",
    "                 'thread', 'lrUpdateRate', 't', 'label', 'verbose', 'pretrainedVectors',\n",
    "                 'seed', 'autotuneValidationFile', 'autotuneMetric',\n",
    "                 'autotunePredictions', 'autotuneDuration', 'autotuneModelSize']\n",
    "    args, manually_set_args = read_args(kargs, kwargs, arg_names,\n",
    "                                        supervised_default)\n",
    "    a = _build_args(args, manually_set_args)\n",
    "    ft = _FastText(args=a)\n",
    "    fasttext.train(ft.f, a)\n",
    "    ft.set_args(ft.f.getArgs())\n",
    "    return ft\n",
    "\n",
    "\n",
    "def train_unsupervised(*kargs, **kwargs):\n",
    "    \"\"\"\n",
    "    Train an unsupervised model and return a model object.\n",
    "\n",
    "    input must be a filepath. The input text does not need to be tokenized\n",
    "    as per the tokenize function, but it must be preprocessed and encoded\n",
    "    as UTF-8. You might want to consult standard preprocessing scripts such\n",
    "    as tokenizer.perl mentioned here: http://www.statmt.org/wmt07/baseline.html\n",
    "\n",
    "    The input field must not contain any labels or use the specified label prefix\n",
    "    unless it is ok for those words to be ignored. For an example consult the\n",
    "    dataset pulled by the example script word-vector-example.sh, which is\n",
    "    part of the fastText repository.\n",
    "    \"\"\"\n",
    "    arg_names = ['input', 'model', 'lr', 'dim', 'ws', 'epoch', 'minCount',\n",
    "                 'minCountLabel', 'minn', 'maxn', 'neg', 'wordNgrams', 'loss', 'bucket',\n",
    "                 'thread', 'lrUpdateRate', 't', 'label', 'verbose', 'pretrainedVectors']\n",
    "    args, manually_set_args = read_args(kargs, kwargs, arg_names,\n",
    "                                        unsupervised_default)\n",
    "    a = _build_args(args, manually_set_args)\n",
    "    ft = _FastText(args=a)\n",
    "    fasttext.train(ft.f, a)\n",
    "    ft.set_args(ft.f.getArgs())\n",
    "    return ft\n",
    "\n",
    "\n",
    "def cbow(*kargs, **kwargs):\n",
    "    raise Exception(\"`cbow` is not supported any more. Please use `train_unsupervised` with model=`cbow`. For more information please refer to https://fasttext.cc/blog/2019/06/25/blog-post.html#2-you-were-using-the-unofficial-fasttext-module\")\n",
    "\n",
    "\n",
    "def skipgram(*kargs, **kwargs):\n",
    "    raise Exception(\"`skipgram` is not supported any more. Please use `train_unsupervised` with model=`skipgram`. For more information please refer to https://fasttext.cc/blog/2019/06/25/blog-post.html#2-you-were-using-the-unofficial-fasttext-module\")\n",
    "\n",
    "\n",
    "def supervised(*kargs, **kwargs):\n",
    "    raise Exception(\"`supervised` is not supported any more. Please use `train_supervised`. For more information please refer to https://fasttext.cc/blog/2019/06/25/blog-post.html#2-you-were-using-the-unofficial-fasttext-module\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
