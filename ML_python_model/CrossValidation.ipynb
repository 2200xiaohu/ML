{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 没有验证集的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score,f1_score,precision_score,recall_score,accuracy_score\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "import lightgbm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def cv(train, test, target,kfold = None):\n",
    "    test_preds = np.zeros((len(test)))\n",
    "    cv = 0\n",
    "    kf = StratifiedKFold(n_splits=kfold, shuffle=True, random_state=42)\n",
    "    train_targets = train[target]\n",
    "    train = train.drop(columns = [target])\n",
    "    \n",
    "    auc_xgb = 0\n",
    "    auc_cat = 0\n",
    "    auc_lgb = 0\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(train, train_targets)):\n",
    "        print(f\"------------> Fold {fold + 1} <-----------------\")\n",
    "        X_train, X_valid = train.iloc[train_idx], train.iloc[valid_idx]\n",
    "        y_train, y_valid = train_targets.iloc[train_idx], train_targets.iloc[valid_idx]\n",
    "        class_weights = [1, len(y_train[y_train == 0]) / len(y_train[y_train == 1])]\n",
    "\n",
    "        ctb = CatBoostClassifier(n_estimators=10000,\n",
    "                                 early_stopping_rounds=100,\n",
    "                                 class_weights=class_weights,\n",
    "                                 **{'depth': 4, 'subsample': 0.9037951675853159, 'l2_leaf_reg': 0.1,\n",
    "                                    'learning_rate': 0.33153188532829714, \"thread_count\": -1,\n",
    "                                    'loss_function': 'Logloss', 'bootstrap_type': 'Bernoulli'})\n",
    "\n",
    "        ctb.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose=0)\n",
    "\n",
    "        ctb_preds = ctb.predict(X_valid)\n",
    "        ctb_test_preds = ctb.predict(test)\n",
    "        \n",
    "        auc_cat +=roc_auc_score(y_valid, ctb_preds)\n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|            CatBoost                |\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(\" \")\n",
    "        print(f\"------------- Train -----------------\")\n",
    "        print(f\"F1 Score: {f1_score(y_valid, ctb_preds)}\")\n",
    "        print(f\"F1-macro Score: {f1_score(y_valid, ctb_preds, average='macro')}\")\n",
    "        print(f\"F1-micro Score: {f1_score(y_valid, ctb_preds, average='micro')}\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_valid, ctb_preds)}\")\n",
    "        print(f\"Precision: {precision_score(y_valid, ctb_preds)}\")\n",
    "        print(f\"Recall: {recall_score(y_valid, ctb_preds)}\")\n",
    "        print(f\"AUC: {roc_auc_score(y_valid, ctb_preds)}\")\n",
    "        print(\" \")\n",
    "\n",
    "        lgb = LGBMClassifier(n_estimators=10000,\n",
    "                             early_stopping_rounds=100,\n",
    "                             class_weight='balanced',\n",
    "                             **{'max_depth': 6,\n",
    "                                'subsample': 0.5528027451731908,\n",
    "                                'colsample_bytree': 1,\n",
    "                                'learning_rate': 0.11430358849370452,\n",
    "                                'bagging_freq': 5,\n",
    "                                'bagging_fraction': 0.6,\n",
    "                                'boost_from_average': 'false',\n",
    "                                'boosting_type': 'gbdt',\n",
    "                                'feature_fraction': 0.5,\n",
    "                                'min_data_in_leaf': 100,\n",
    "                                'min_sum_hessian_in_leaf': 100.0,\n",
    "                                'num_leaves': 2 ** 4,\n",
    "                                'objective': 'binary', 'n_jobs': -1})\n",
    "\n",
    "        lgb.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose=0)\n",
    "\n",
    "        lgb_preds = lgb.predict(X_valid)\n",
    "        lgb_test_preds = lgb.predict(test)\n",
    "        \n",
    "        auc_lgb +=roc_auc_score(y_valid, lgb_preds)\n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|            LightGBM                |\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(\" \")\n",
    "        print(f\"------------- Train -----------------\")\n",
    "        print(f\"F1 Score: {f1_score(y_valid, lgb_preds)}\")\n",
    "        print(f\"F1-macro Score: {f1_score(y_valid, lgb_preds, average='macro')}\")\n",
    "        print(f\"F1-micro Score: {f1_score(y_valid, lgb_preds, average='micro')}\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_valid, lgb_preds)}\")\n",
    "        print(f\"Precision: {precision_score(y_valid, lgb_preds)}\")\n",
    "        print(f\"Recall: {recall_score(y_valid, lgb_preds)}\")\n",
    "        print(f\"AUC: {roc_auc_score(y_valid, lgb_preds)}\")\n",
    "\n",
    "        xgb = XGBClassifier(n_estimators=10000,\n",
    "                            early_stopping_rounds=100,\n",
    "                            **{'max_depth': 6, 'subsample': 0.5549531235327668,\n",
    "                               'scale_pos_weight':sum(y_train == 0) / sum(y_train == 1),\n",
    "                               'colsample_bytree': 1,\n",
    "                               'learning_rate': 0.15, 'objective': 'binary:logistic', 'n_jobs': -1})\n",
    "\n",
    "        xgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=0)\n",
    "\n",
    "        xgb_preds = xgb.predict(X_valid)\n",
    "        xgb_test_preds = xgb.predict(test)\n",
    "        \n",
    "        auc_xgb +=roc_auc_score(y_valid, xgb_preds)\n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|            XGBoost                 |\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(\" \")\n",
    "        print(f\"------------- Train -----------------\")\n",
    "        print(f\"F1 Score: {f1_score(y_valid, xgb_preds)}\")\n",
    "        print(f\"F1-macro Score: {f1_score(y_valid, xgb_preds, average='macro')}\")\n",
    "        print(f\"F1-micro Score: {f1_score(y_valid, xgb_preds, average='micro')}\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_valid, xgb_preds)}\")\n",
    "        print(f\"Precision: {precision_score(y_valid, xgb_preds)}\")\n",
    "        print(f\"Recall: {recall_score(y_valid, xgb_preds)}\")\n",
    "        print(f\"AUC: {roc_auc_score(y_valid, xgb_preds)}\")\n",
    "\n",
    "        meta_train = [lgb_preds, ctb_preds, xgb_preds]\n",
    "        meta_test = [lgb_test_preds, ctb_test_preds, xgb_test_preds]\n",
    "    print(f\"cat Auc average: {auc_cat/kfold}\")\n",
    "    print(f\"lgb Auc average: {auc_lgb/kfold}\")\n",
    "    print(f\"xgb Auc average: {auc_xgb/kfold}\")\n",
    "    print(f\"CV: {cv/(fold+1)}\")\n",
    "    \n",
    "    return meta_train,meta_test\n",
    "\n",
    "_ , pred_test = cv(train = train, test = test.drop(columns = ['Severity']), target = 'Severity',kfold=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_score(y_true,y_pred):\n",
    "    print(f\"F1 Score: {f1_score(y_true, y_pred)}\")\n",
    "    print(f\"F1-macro Score: {f1_score(y_true, y_pred, average='macro')}\")\n",
    "    print(f\"F1-micro Score: {f1_score(y_true, y_pred, average='micro')}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y_true, y_pred)}\")\n",
    "    print(f\"AUC: {roc_auc_score(y_true, y_pred)}\")\n",
    "    \n",
    "for i in range(3):\n",
    "    print(\"-\"*20)\n",
    "    test_score(test['Severity'],pred_test[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 带有验证集的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score,f1_score,precision_score,recall_score,accuracy_score\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "import lightgbm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def cv_withVal(train, val, test, target):\n",
    "    test_preds = np.zeros((len(test)))\n",
    "    val_preds = np.zeros((len(val)))\n",
    "    cv = 0\n",
    "    kf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    train_targets = train[target]\n",
    "    train = train.drop(columns = [target])\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(train, train_targets)):\n",
    "        print(\"-\" * 10 + \">\" + f\"Fold {fold + 1}\" + \"<\" + \"-\" * 10)\n",
    "        X_train, X_valid = train.iloc[train_idx], train.iloc[valid_idx]\n",
    "        y_train, y_valid = train_targets.iloc[train_idx], train_targets.iloc[valid_idx]\n",
    "        class_weights = [1, len(y_train[y_train == 0]) / len(y_train[y_train == 1])]\n",
    "\n",
    "        ctb = CatBoostClassifier(n_estimators=10000,\n",
    "                                 early_stopping_rounds=100,\n",
    "                                 class_weights=class_weights,\n",
    "                                 **{'depth': 4, 'subsample': 0.9037951675853159, 'l2_leaf_reg': 4.085968446512874,\n",
    "                                    'learning_rate': 0.33153188532829714, \"thread_count\": -1,\n",
    "                                    'loss_function': 'Logloss', 'bootstrap_type': 'Bernoulli'})\n",
    "\n",
    "        ctb.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose=0)\n",
    "\n",
    "        ctb_preds = ctb.predict(X_valid)\n",
    "        ctb_val_preds = ctb.predict(val.drop(columns = [target]))\n",
    "        ctb_test_preds = ctb.predict(test)\n",
    "\n",
    "        print(f\"------------- Train -----------------\")\n",
    "        print(f\"F1 Score: {f1_score(y_valid, ctb_preds)}\")\n",
    "        print(f\"F1-macro Score: {f1_score(y_valid, ctb_preds, average='macro')}\")\n",
    "        print(f\"F1-micro Score: {f1_score(y_valid, ctb_preds, average='micro')}\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_valid, ctb_preds)}\")\n",
    "        print(f\"Precision: {precision_score(y_valid, ctb_preds)}\")\n",
    "        print(f\"Recall: {recall_score(y_valid, ctb_preds)}\")\n",
    "        print(f\"AUC: {roc_auc_score(y_valid, ctb_preds)}\")\n",
    "\n",
    "        print(f\"------------- val -----------------\")\n",
    "        print(f\"F1 Score: {f1_score(y_val, ctb_val_preds)}\")\n",
    "        print(f\"F1-macro Score: {f1_score(y_val, ctb_val_preds, average='macro')}\")\n",
    "        print(f\"F1-micro Score: {f1_score(y_val, ctb_val_preds, average='micro')}\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_val, ctb_val_preds)}\")\n",
    "        print(f\"Precision: {precision_score(y_val, ctb_val_preds)}\")\n",
    "        print(f\"Recall: {recall_score(y_val, ctb_val_preds)}\")\n",
    "        print(f\"AUC: {roc_auc_score(y_val, ctb_val_preds)}\")\n",
    "\n",
    "        print(\" \")\n",
    "\n",
    "        lgb = LGBMClassifier(n_estimators=10000,\n",
    "                             early_stopping_rounds=100,\n",
    "                             class_weight='balanced',\n",
    "                             **{'max_depth': 5,\n",
    "                                'subsample': 0.5528027451731908,\n",
    "                                'colsample_bytree': 0.26714040676512085,\n",
    "                                'learning_rate': 0.11430358849370452,\n",
    "                                'bagging_freq': 5,\n",
    "                                'bagging_fraction': 0.6,\n",
    "                                'boost_from_average': 'false',\n",
    "                                'boosting_type': 'gbdt',\n",
    "                                'feature_fraction': 0.5,\n",
    "                                'min_data_in_leaf': 100,\n",
    "                                'min_sum_hessian_in_leaf': 100.0,\n",
    "                                'num_leaves': 2 ** 4,\n",
    "                                'objective': 'binary', 'n_jobs': -1})\n",
    "\n",
    "        lgb.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose=0)\n",
    "\n",
    "        lgb_preds = lgb.predict(X_valid)\n",
    "        lgb_val_preds = lgb.predict(val.drop(columns = [target]))\n",
    "        lgb_test_preds = lgb.predict(test)\n",
    "\n",
    "        print(f\"------------- Train -----------------\")\n",
    "        print(f\"F1 Score: {f1_score(y_valid, lgb_preds)}\")\n",
    "        print(f\"F1-macro Score: {f1_score(y_valid, lgb_preds, average='macro')}\")\n",
    "        print(f\"F1-micro Score: {f1_score(y_valid, lgb_preds, average='micro')}\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_valid, lgb_preds)}\")\n",
    "        print(f\"Precision: {precision_score(y_valid, lgb_preds)}\")\n",
    "        print(f\"Recall: {recall_score(y_valid, lgb_preds)}\")\n",
    "        print(f\"AUC: {roc_auc_score(y_valid, lgb_preds)}\")\n",
    "\n",
    "        print(f\"------------- val -----------------\")\n",
    "        print(f\"F1 Score: {f1_score(y_val, lgb_val_preds)}\")\n",
    "        print(f\"F1-macro Score: {f1_score(y_val, lgb_val_preds, average='macro')}\")\n",
    "        print(f\"F1-micro Score: {f1_score(y_val, lgb_val_preds, average='micro')}\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_val, lgb_val_preds)}\")\n",
    "        print(f\"Precision: {precision_score(y_val, lgb_val_preds)}\")\n",
    "        print(f\"Recall: {recall_score(y_val, lgb_val_preds)}\")\n",
    "        print(f\"AUC: {roc_auc_score(y_val, lgb_val_preds)}\")\n",
    "        print(\" \")\n",
    "\n",
    "        xgb = XGBClassifier(n_estimators=10000,\n",
    "                            early_stopping_rounds=100,\n",
    "                            **{'max_depth': 6, 'subsample': 0.5549531235327668,\n",
    "                               'scale_pos_weight':sum(y_train == 0) / sum(y_train == 1),\n",
    "                               'colsample_bytree': 0.20335345531973037,\n",
    "                               'learning_rate': 0.027251718255125106, 'objective': 'binary:logistic', 'n_jobs': -1})\n",
    "\n",
    "        xgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=0)\n",
    "\n",
    "        xgb_preds = xgb.predict(X_valid)\n",
    "        xgb_val_preds = xgb.predict(val.drop(columns = [target]))\n",
    "        xgb_test_preds = xgb.predict(test)\n",
    "\n",
    "        print(f\"------------- Train -----------------\")\n",
    "        print(f\"F1 Score: {f1_score(y_valid, xgb_preds)}\")\n",
    "        print(f\"F1-macro Score: {f1_score(y_valid, xgb_preds, average='macro')}\")\n",
    "        print(f\"F1-micro Score: {f1_score(y_valid, xgb_preds, average='micro')}\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_valid, xgb_preds)}\")\n",
    "        print(f\"Precision: {precision_score(y_valid, xgb_preds)}\")\n",
    "        print(f\"Recall: {recall_score(y_valid, xgb_preds)}\")\n",
    "        print(f\"AUC: {roc_auc_score(y_valid, xgb_preds)}\")\n",
    "\n",
    "        print(f\"------------- val -----------------\")\n",
    "        print(f\"F1 Score: {f1_score(y_val, xgb_val_preds)}\")\n",
    "        print(f\"F1-macro Score: {f1_score(y_val, xgb_val_preds, average='macro')}\")\n",
    "        print(f\"F1-micro Score: {f1_score(y_val, xgb_val_preds, average='micro')}\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_val, xgb_val_preds)}\")\n",
    "        print(f\"Precision: {precision_score(y_val, xgb_val_preds)}\")\n",
    "        print(f\"Recall: {recall_score(y_val, xgb_val_preds)}\")\n",
    "        print(f\"AUC: {roc_auc_score(y_val, xgb_val_preds)}\")\n",
    "        print(\" \")\n",
    "\n",
    "        meta_train = [lgb_preds, ctb_preds, xgb_preds]\n",
    "        meta_test = [lgb_test_preds, ctb_test_preds, xgb_test_preds]\n",
    "        meta_val = [lgb_val_preds, ctb_val_preds, xgb_val_preds]\n",
    "\n",
    "    print(f\"CV: {cv/(fold+1)}\")\n",
    "    \n",
    "    return meta_train, meta_val, meta_test\n",
    "\n",
    "_ , pred_val, pred_test = cv(train = pd.concat([x_train,y_train],axis =1).reset_index(drop=True), val = pd.concat([x_val,y_val],axis =1).reset_index(drop=True), \n",
    "                             test = test.drop(columns = ['Severity']), target = 'Severity')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
