{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score,f1_score,precision_score,recall_score\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "import lightgbm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "val =  pd.read_csv('val.csv')\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train['label'][train.label==1] = 0\n",
    "train['label'][train.label!=0] = 1\n",
    "\n",
    "val['label'][val.label==1] = 0\n",
    "val['label'][val.label!=0] = 1\n",
    "\n",
    "train_targets = train['label']\n",
    "train.drop(\"label\", axis=1, inplace=True)\n",
    "y_val = val['label']\n",
    "val.drop(\"label\", axis=1, inplace=True)\n",
    "\n",
    "def cus_F1(y_true = None,y_pred = None):\n",
    "    p = precision_score(y_true,y_pred,average='macro')\n",
    "    r = recall_score(y_true,y_pred,average='macro')\n",
    "    return float(2*p*r/(p+r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score,f1_score,precision_score,recall_score,accuracy_score\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "import lightgbm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import plot_metric\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def cv(train, test, target,kfold = None):\n",
    "    test_preds = np.zeros((len(test)))\n",
    "    cv = 0\n",
    "    kf = StratifiedKFold(n_splits=kfold, shuffle=True, random_state=42)\n",
    "    train_targets = train[target]\n",
    "    train = train.drop(columns = [target])\n",
    "    \n",
    "    auc_xgb = 0\n",
    "    auc_cat = 0\n",
    "    auc_lgb = 0\n",
    "    \n",
    "    recall_xgb = 0\n",
    "    recall_lgb = 0\n",
    "    recall_cat = 0\n",
    "    \n",
    "    test_preds = np.zeros((len(test)))\n",
    "    val_preds = np.zeros((len(train)))\n",
    "    \n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(train, train_targets)):\n",
    "        print(f\"------------> Fold {fold + 1} <-----------------\")\n",
    "        X_train, X_valid = train.iloc[train_idx], train.iloc[valid_idx]\n",
    "        y_train, y_valid = train_targets.iloc[train_idx], train_targets.iloc[valid_idx]\n",
    "        class_weights = [1, len(y_train[y_train == 0]) / len(y_train[y_train == 1])*1.03]\n",
    "\n",
    "        ctb = CatBoostClassifier(n_estimators=10000,\n",
    "                                 early_stopping_rounds=30,\n",
    "                                 class_weights=class_weights,\n",
    "                                 **{'depth': 2*4, 'subsample': 0.8, 'l2_leaf_reg': 0.15,\n",
    "                                    'learning_rate': 0.05, \"thread_count\": -1,\n",
    "                                    'loss_function': 'Logloss', 'bootstrap_type': 'Bernoulli'})\n",
    "\n",
    "        ctb.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose=0)\n",
    "\n",
    "        ctb_preds = ctb.predict(X_valid)\n",
    "        ctb_test_preds = ctb.predict(test)\n",
    "        \n",
    "        ctb_preds_prb = ctb.predict_proba(X_valid)[:,-1]\n",
    "        ctb_test_preds_prb = ctb.predict_proba(test)[:,-1]\n",
    "        \n",
    "        auc_cat +=roc_auc_score(y_valid, ctb_preds)\n",
    "        recall_cat += recall_score(y_valid, ctb_preds)\n",
    "        \n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|            CatBoost                |\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(\" \")\n",
    "        print(f\"------------- Train -----------------\")\n",
    "        print(f\"F1 Score: {f1_score(y_valid, ctb_preds)}\")\n",
    "        print(f\"F1-macro Score: {f1_score(y_valid, ctb_preds, average='macro')}\")\n",
    "        print(f\"F1-micro Score: {f1_score(y_valid, ctb_preds, average='micro')}\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_valid, ctb_preds)}\")\n",
    "        print(f\"Precision: {precision_score(y_valid, ctb_preds)}\")\n",
    "        print(f\"Recall: {recall_score(y_valid, ctb_preds)}\")\n",
    "        print(f\"AUC: {roc_auc_score(y_valid, ctb_preds)}\")\n",
    "        print(\" \")\n",
    "        \n",
    "\n",
    "        lgb = LGBMClassifier(n_estimators=10000,\n",
    "                             early_stopping_rounds=30,#is_unbalance=True,\n",
    "                             scale_pos_weight=sum(y_train == 0) / sum(y_train == 1)*1.1,\n",
    "                             **{'max_depth': -1,\n",
    "                                'subsample': 0.8,\n",
    "                                'colsample_bytree': 1,\n",
    "                                'learning_rate': 0.05,\n",
    "                                'bagging_freq': 5,\n",
    "                                'bagging_fraction': 1,\n",
    "                                'boost_from_average': 'false',\n",
    "                                'boosting_type': 'gbdt',\n",
    "                                'feature_fraction': 1,\n",
    "                                'min_data_in_leaf': 10,\n",
    "                                'min_sum_hessian_in_leaf': 10.0,\n",
    "                                'num_leaves': 2**8,\n",
    "                                'objective': 'binary', 'n_jobs': -1})\n",
    "        lgb.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose=0, eval_metric='average_precision')\n",
    "        \n",
    "        plot_metric(lgb,'average_precision')\n",
    "        \n",
    "        lgb_preds = lgb.predict(X_valid)\n",
    "        lgb_test_preds = lgb.predict(test)\n",
    "        \n",
    "        lgb_preds_prb = lgb.predict_proba(X_valid)[:,-1]\n",
    "        lgb_test_preds_prb = lgb.predict_proba(test)[:,-1]\n",
    "        \n",
    "        auc_lgb +=roc_auc_score(y_valid, lgb_preds)\n",
    "        recall_lgb += recall_score(y_valid, lgb_preds)\n",
    "        \n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|            LightGBM                |\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(\" \")\n",
    "        print(f\"------------- Train -----------------\")\n",
    "        print(f\"F1 Score: {f1_score(y_valid, lgb_preds)}\")\n",
    "        print(f\"F1-macro Score: {f1_score(y_valid, lgb_preds, average='macro')}\")\n",
    "        print(f\"F1-micro Score: {f1_score(y_valid, lgb_preds, average='micro')}\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_valid, lgb_preds)}\")\n",
    "        print(f\"Precision: {precision_score(y_valid, lgb_preds)}\")\n",
    "        print(f\"Recall: {recall_score(y_valid, lgb_preds)}\")\n",
    "        print(f\"AUC: {roc_auc_score(y_valid, lgb_preds)}\")\n",
    "        \n",
    "        \n",
    "        xgb = XGBClassifier(n_estimators=10000,\n",
    "                            early_stopping_rounds=100,\n",
    "                            **{'max_depth': 6, 'subsample': 0.8,\n",
    "                               'scale_pos_weight':sum(y_train == 0) / sum(y_train == 1),\n",
    "                               'colsample_bytree': 1,'max_leaves':0,\n",
    "                               'learning_rate': 0.1, 'objective': 'binary:logistic', 'n_jobs': -1})\n",
    "\n",
    "        xgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=0)\n",
    "\n",
    "        xgb_preds = xgb.predict(X_valid)\n",
    "        xgb_test_preds = xgb.predict(test)\n",
    "        \n",
    "        xgb_preds_prb = xgb.predict_proba(X_valid)[:,-1]\n",
    "        xgb_test_preds_prb = xgb.predict_proba(test)[:,-1]\n",
    "        \n",
    "        auc_xgb +=roc_auc_score(y_valid, xgb_preds)\n",
    "        recall_xgb += recall_score(y_valid, xgb_preds)\n",
    "        \n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|            XGBoost                 |\")\n",
    "        print(f\"|                                    |\")\n",
    "        print(f\"|------------------------------------|\")\n",
    "        print(\" \")\n",
    "        print(f\"------------- Train -----------------\")\n",
    "        print(f\"F1 Score: {f1_score(y_valid, xgb_preds)}\")\n",
    "        print(f\"F1-macro Score: {f1_score(y_valid, xgb_preds, average='macro')}\")\n",
    "        print(f\"F1-micro Score: {f1_score(y_valid, xgb_preds, average='micro')}\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_valid, xgb_preds)}\")\n",
    "        print(f\"Precision: {precision_score(y_valid, xgb_preds)}\")\n",
    "        print(f\"Recall: {recall_score(y_valid, xgb_preds)}\")\n",
    "        print(f\"AUC: {roc_auc_score(y_valid, xgb_preds)}\")\n",
    "        \n",
    "        meta_train = [lgb_preds, ctb_preds, xgb_preds]\n",
    "        meta_test = [lgb_test_preds, ctb_test_preds, xgb_test_preds]\n",
    "\n",
    "        prob_train = [ctb_preds_prb,lgb_preds_prb,xgb_preds_prb]\n",
    "        prob_test = [ctb_test_preds_prb,lgb_test_preds_prb,xgb_test_preds_prb]\n",
    "\n",
    "        # meta_train = [ctb_preds,lgb_preds]\n",
    "        # meta_test = [ctb_test_preds,lgb_test_preds]\n",
    "        \n",
    "        # prob_train = [ctb_preds_prb,lgb_preds_prb]\n",
    "        # prob_test = [ctb_test_preds_prb,lgb_test_preds_prb]\n",
    "        \n",
    "        def f1_loss(weights):\n",
    "            fpred = np.zeros(len(meta_train[0]))\n",
    "            for i, pred in enumerate(prob_train):\n",
    "                fpred += weights[i] * pred\n",
    "\n",
    "            return -roc_auc_score(y_valid, fpred)\n",
    "\n",
    "\n",
    "        starting_values = [np.float64(random.uniform(0, 1))]*len(meta_train) \n",
    "        print(f\"starting_values is :{starting_values}\")\n",
    "        cons = ({'type':'eq','fun':lambda w: 1-sum(w)})\n",
    "        bounds = [(-1,1)]*len(meta_train) \n",
    "        res = minimize(f1_loss, starting_values, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "        print(\"------------\")\n",
    "        print(\"fun is \")\n",
    "        print(-res[\"fun\"])\n",
    "\n",
    "        cv -= res[\"fun\"]\n",
    "        \n",
    "        for i, pred in enumerate(prob_test):\n",
    "            print(\"res x i is \")\n",
    "            print(res[\"x\"][i])\n",
    "            print(\"pred is \")\n",
    "            print(pred)\n",
    "            test_preds += res[\"x\"][i] * pred#简单的加总每次CV的结果\n",
    "\n",
    "    \n",
    "    print(f\"cat Auc average: {auc_cat/kfold}\")\n",
    "    print(f\"lgb Auc average: {auc_lgb/kfold}\")\n",
    "    # print(f\"xgb Auc average: {auc_xgb/kfold}\")\n",
    "    print(f\"cat recall average: {recall_cat/kfold}\")\n",
    "    print(f\"lgb recall average: {recall_lgb/kfold}\")\n",
    "    # print(f\"xgb recall average: {recall_xgb/kfold}\")\n",
    "    \n",
    "    test_preds /= kfold\n",
    "\n",
    "    print(f\"CV: {cv/kfold}\")\n",
    "    \n",
    "    return meta_train,meta_test,test_preds\n",
    "\n",
    "_ , pred_test,ensemble_test = cv(train = train, test = test.drop(columns = ['Severity']), target = 'Severity',kfold=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_score(y_true,y_pred):\n",
    "    print(f\"F1 Score: {f1_score(y_true, y_pred)}\")\n",
    "    print(f\"F1-macro Score: {f1_score(y_true, y_pred, average='macro')}\")\n",
    "    print(f\"F1-micro Score: {f1_score(y_true, y_pred, average='micro')}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y_true, y_pred)}\")\n",
    "    print(f\"AUC: {roc_auc_score(y_true, y_pred)}\")\n",
    "    \n",
    "for i in range(2):\n",
    "    print(\"-\"*20)\n",
    "    test_score(test['Severity'],pred_test[i])\n",
    "\n",
    "\n",
    "print(\"-\"*20)\n",
    "test_score(test['Severity'],(ensemble_test > 0.5).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = np.argmax(test_preds,axis=1)\n",
    "re_val = np.argmax(val_preds,axis=1)\n",
    "print(f\"final val custom F1 score is{cus_F1(re_val,y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "predictions_dict = {str(i):int(re[i]) for i in range(len(re))}\n",
    "with open(\"submit.json\", \"w\") as outfile:\n",
    "    json.dump(predictions_dict, outfile)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
